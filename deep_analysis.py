"""
ç‹¬ç«‹çš„æ·±åº¦åˆ†æè„šæœ¬
ç”¨æ³•: python deep_analysis.py [--input INPUT_FILE] [--output OUTPUT_FILE]
"""

import json
import os
import argparse
from time import perf_counter
from src.until.config_loader import load_config
from src.models.qwen_model import QwenModel
from src.analyzer.response_analyse import ResponseAnalyzer
from src.analyzer.deep_analyzer import DeepAnalyzer
from src.analyzer.result_statistics import print_stage2_statistics  # âœ¨ å¯¼å…¥ç»Ÿè®¡å‡½æ•°


def load_anomalous_urls(input_file: str):
    """
    ä»ç¬¬ä¸€é˜¶æ®µç»“æœæ–‡ä»¶æˆ–URLåˆ—è¡¨æ–‡ä»¶åŠ è½½å¼‚å¸¸URL
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ (.json æˆ– .txt)
        
    Returns:
        list: å¼‚å¸¸URLç»“æœåˆ—è¡¨
    """
    if not os.path.exists(input_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return []
    
    # æ ¹æ®æ–‡ä»¶æ‰©å±•ååˆ¤æ–­æ–‡ä»¶ç±»å‹
    _, ext = os.path.splitext(input_file)
    
    if ext == '.json':
        # ä»JSONæ–‡ä»¶åŠ è½½
        with open(input_file, 'r', encoding='utf-8') as f:
            all_results = json.load(f)
        
        # ç­›é€‰å‡ºå¼‚å¸¸URL
        anomalous_results = [r for r in all_results if r.get('predicted') == "1"]
        print(f"ğŸ“Š ä» {input_file} åŠ è½½äº† {len(anomalous_results)} ä¸ªå¼‚å¸¸URL")
        return anomalous_results
    
    elif ext == '.txt':
        # ä»TXTæ–‡ä»¶åŠ è½½URLåˆ—è¡¨
        with open(input_file, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip()]
        
        # æ„é€ åŸºæœ¬ç»“æœç»“æ„
        anomalous_results = [
            {
                "url": url,
                "predicted": "1",
                "attack_type": "unknown",
                "detection_method": "manual"
            }
            for url in urls
        ]
        print(f"ğŸ“Š ä» {input_file} åŠ è½½äº† {len(urls)} ä¸ªURL")
        return anomalous_results
    
    else:
        print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext} (ä»…æ”¯æŒ .json æˆ– .txt)")
        return []


def main():
    """ä¸»å‡½æ•°ï¼šç‹¬ç«‹æ·±åº¦åˆ†ææµç¨‹"""
    
    # ========== è§£æå‘½ä»¤è¡Œå‚æ•° ==========
    parser = argparse.ArgumentParser(
        description="URLå®‰å…¨æ£€æµ‹ - æ·±åº¦åˆ†ææ¨¡å—",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  1. ä½¿ç”¨é»˜è®¤é…ç½®:
     python deep_analysis.py
  
  2. æŒ‡å®šè¾“å…¥æ–‡ä»¶:
     python deep_analysis.py --input output/stage1_realtime_all.json
  
  3. æŒ‡å®šè¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶:
     python deep_analysis.py --input output/stage1_anomalous.txt --output output/custom_analysis.json
        """
    )
    
    parser.add_argument(
        '--input', '-i',
        type=str,
        default=None,
        help='è¾“å…¥æ–‡ä»¶è·¯å¾„ (æ”¯æŒ .json æˆ– .txt æ ¼å¼)'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        default=None,
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: output/stage2_deep_analysis.json)'
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        default='./config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./config.yaml)'
    )
    
    args = parser.parse_args()
    
    # ========== åŠ è½½é…ç½® ==========
    config = load_config(args.config)
    
    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    if args.input:
        input_file = args.input
    else:
        # é»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ç¬¬ä¸€é˜¶æ®µè¾“å‡º
        input_file = os.path.join(
            config['output']['dir'],
            config['output']['stage1_all']
        )
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶
    if args.output:
        output_file = args.output
    else:
        output_file = os.path.join(
            config['output']['dir'],
            config['output']['stage2_deep_analysis']
        )
    
    # ========== åˆå§‹åŒ–æ¨¡å‹ ==========
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ URLå®‰å…¨æ£€æµ‹ - æ·±åº¦åˆ†ææ¨¡å—")
    print(f"{'='*60}")
    print(f"ğŸ“‚ è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"{'='*60}\n")
    
    model = QwenModel(
        model_path=config['model']['path'],
        dtype=config['model']['dtype']
    )
    parser_analyzer = ResponseAnalyzer()
    
    # ========== åŠ è½½å¼‚å¸¸URL ==========
    anomalous_results = load_anomalous_urls(input_file)
    
    if len(anomalous_results) == 0:
        print("âœ… æœªæ‰¾åˆ°å¼‚å¸¸URLï¼Œé€€å‡ºæ·±åº¦åˆ†æ")
        return
    
    # ========== æ‰§è¡Œæ·±åº¦åˆ†æ ==========
    deep_analyzer = DeepAnalyzer(model, parser_analyzer, config)
    stage2_start = perf_counter()
    
    deep_results = deep_analyzer.batch_analyze(anomalous_results)
    
    stage2_elapsed = perf_counter() - stage2_start
    
    # ========== ä¿å­˜ç»“æœ ==========
    output_dir = os.path.dirname(output_file)
    os.makedirs(output_dir, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(deep_results, f, ensure_ascii=False, indent=2)
    
    # ========== ä½¿ç”¨ç»Ÿä¸€çš„ç»Ÿè®¡å‡½æ•° ==========
    print_stage2_statistics(stage2_elapsed, output_file, deep_results)
    
    # ========== æ”»å‡»ç±»å‹ç»Ÿè®¡ ==========
    attack_type_count = {}
    for result in deep_results:
        attack_type = result.get('attack_type', 'unknown')
        attack_type_count[attack_type] = attack_type_count.get(attack_type, 0) + 1
    
    print(f"\nğŸ“Š æ”»å‡»ç±»å‹åˆ†å¸ƒ:")
    print(f"{'='*60}")
    for attack_type, count in sorted(attack_type_count.items(), key=lambda x: x[1], reverse=True):
        percentage = count / len(deep_results) * 100
        print(f"  {attack_type:20s}: {count:3d} ä¸ª ({percentage:.1f}%)")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()