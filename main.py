import json
import os
import argparse
from time import perf_counter
from src.until.config_loader import load_config
from src.models.qwen_model import QwenModel
from src.analyzer.response_analyse import ResponseAnalyzer
from src.analyzer.hybrid_detector import HybridDetector
from src.analyzer.deep_analyzer import DeepAnalyzer
from src.rules.rule_loader import load_rule_engine
from src.until.until import process_file
from src.analyzer.result_statistics import (
    analyze_results,
    print_stage2_statistics,
    print_two_stage_summary
)


def main():
    """ä¸»å‡½æ•°ï¼šä¸¤é˜¶æ®µæ£€æµ‹æµç¨‹"""
    
    # ========== è§£æå‘½ä»¤è¡Œå‚æ•° ==========
    parser = argparse.ArgumentParser(
        description="URLå®‰å…¨æ£€æµ‹ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  1. å®Œæ•´æ£€æµ‹ï¼ˆåŒ…å«æ·±åº¦åˆ†æï¼‰:
     python main.py
  
  2. ä»…ç¬¬ä¸€é˜¶æ®µæ£€æµ‹ï¼ˆè·³è¿‡æ·±åº¦åˆ†æï¼‰:
     python main.py --skip-deep-analysis
  
  3. ä½¿ç”¨è‡ªå®šä¹‰é…ç½®:
     python main.py --config custom_config.yaml
        """
    )
    
    parser.add_argument(
        '--skip-deep-analysis',
        action='store_true',
        help='è·³è¿‡ç¬¬äºŒé˜¶æ®µæ·±åº¦åˆ†æï¼ˆä»…æ‰§è¡Œå¿«é€Ÿæ£€æµ‹ï¼‰'
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        default='./config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./config.yaml)'
    )
    
    args = parser.parse_args()
    
    # ========== åˆå§‹åŒ– ==========
    config = load_config(args.config)
    model = QwenModel(
        model_path=config['model']['path'],
        dtype=config['model']['dtype']
    )
    parser_analyzer = ResponseAnalyzer()
    rule_engine = load_rule_engine(config.get('rules', {}))
    
    # ========== ç¬¬ä¸€é˜¶æ®µï¼šå®æ—¶ç›‘æµ‹ï¼ˆå¿«é€Ÿåˆ¤å®šï¼‰ ==========
    print(f"\n{'='*60}")
    print(f"âš¡ ç¬¬ä¸€é˜¶æ®µï¼šå®æ—¶ç›‘æµ‹ - å¿«é€Ÿåˆ¤å®š")
    print(f"{'='*60}\n")
    
    detector = HybridDetector(model, parser_analyzer, rule_engine, config)
    stage1_start = perf_counter()
    
    # å¤„ç†æ­£å¸¸URL
    good_results = process_file(
        filename=config['data']['normal_file'],
        label="normal",
        query_func=detector.detect,
        data_dir=config['data']['dir']
    )
    
    # å¤„ç†æ”»å‡»URL
    bad_results = process_file(
        filename=config['data']['attack_file'],
        label="attack",
        query_func=detector.detect,
        data_dir=config['data']['dir']
    )
    
    all_stage1_results = good_results + bad_results
    stage1_elapsed = perf_counter() - stage1_start
    
    # ç­›é€‰å¼‚å¸¸URL
    anomalous_results = [r for r in all_stage1_results if r['predicted'] == "1"]
    
    # ä¿å­˜å¼‚å¸¸URLåˆ—è¡¨ï¼ˆç”¨äºç¬¬äºŒé˜¶æ®µï¼‰
    output_dir = config['output']['dir']
    os.makedirs(output_dir, exist_ok=True)
    
    stage1_anomalous_file = os.path.join(output_dir, config['output']['stage1_anomalous'])
    with open(stage1_anomalous_file, 'w', encoding='utf-8') as f:
        for item in anomalous_results:
            f.write(f"{item['url']}\n")

    print(f"ğŸ’¾ å¼‚å¸¸URLåˆ—è¡¨å·²ä¿å­˜: {stage1_anomalous_file}")
    
    # ========== ç¬¬äºŒé˜¶æ®µï¼šç¦»çº¿æ·±åº¦åˆ†æï¼ˆå¯é€‰ï¼‰ ==========
    if args.skip_deep_analysis:
        print(f"\n{'='*60}")
        print(f"â­ï¸  è·³è¿‡ç¬¬äºŒé˜¶æ®µæ·±åº¦åˆ†æ")
        print(f"{'='*60}")
        print(f"ğŸ’¡ æç¤º: å¦‚éœ€æ·±åº¦åˆ†æï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤:")
        stage1_all_file = os.path.join(output_dir, config['output']['stage1_all'])
        print(f"   python deep_analysis.py --input {stage1_all_file}")
        print(f"{'='*60}\n")

        # åªè¿›è¡Œç¬¬ä¸€é˜¶æ®µè¯„ä¼°
        analyze_results(all_stage1_results, config['output'], stage1_elapsed)

    else:
        if len(anomalous_results) == 0:
            print("\nâœ… æœªæ£€æµ‹åˆ°å¼‚å¸¸URLï¼Œè·³è¿‡ç¬¬äºŒé˜¶æ®µåˆ†æ")
            # è¿›è¡Œç¬¬ä¸€é˜¶æ®µè¯„ä¼°
            analyze_results(all_stage1_results, config['output'], stage1_elapsed)
        else:
            # æ‰§è¡Œæ·±åº¦åˆ†æ
            deep_analyzer = DeepAnalyzer(model, parser_analyzer, config)
            stage2_start = perf_counter()

            deep_results = deep_analyzer.batch_analyze(anomalous_results)

            stage2_elapsed = perf_counter() - stage2_start

            # ä¿å­˜ç¬¬äºŒé˜¶æ®µç»“æœ
            stage2_file = os.path.join(output_dir, config['output']['stage2_deep_analysis'])
            with open(stage2_file, 'w', encoding='utf-8') as f:
                json.dump(deep_results, f, ensure_ascii=False, indent=2)

            # æ‰“å°ç¬¬äºŒé˜¶æ®µç»Ÿè®¡
            print_stage2_statistics(stage2_elapsed, stage2_file, deep_results)

            # æ‰“å°ä¸¤é˜¶æ®µæ€»ç»“
            print_two_stage_summary(stage1_elapsed, stage2_elapsed)

            # è¿›è¡Œç¬¬ä¸€é˜¶æ®µè¯¦ç»†è¯„ä¼°
            analyze_results(all_stage1_results, config['output'], stage1_elapsed)


if __name__ == "__main__":
    main()