"""FAISSå‘é‡å­˜å‚¨ç®¡ç†å™¨"""
import faiss
import numpy as np
import pickle
from typing import List, Tuple, Optional
from sentence_transformers import SentenceTransformer


class VectorStore:
    """FAISSå‘é‡å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, model_name: str = "BAAI/bge-small-zh-v1.5", dimension: int = 512):
        """
        åˆå§‹åŒ–å‘é‡å­˜å‚¨
        
        Args:
            model_name: SentenceTransformeræ¨¡å‹åç§°
            dimension: å‘é‡ç»´åº¦
        """
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½BGEæ¨¡å‹: {model_name}")
        self.model = SentenceTransformer(model_name)
        self.dimension = dimension
        self.index = None
        self.metadata = []
        print(f"âœ… BGEæ¨¡å‹åŠ è½½å®Œæˆ")
    
    def encode(self, texts: List[str]) -> np.ndarray:
        """
        å°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            np.ndarray: å‘é‡æ•°ç»„ (N, dimension)
        """
        # âœ… å½’ä¸€åŒ–å‘é‡ï¼ˆä½¿å†…ç§¯ = ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        embeddings = self.model.encode(
            texts,
            normalize_embeddings=True,  # â† å…³é”®ï¼šå½’ä¸€åŒ–
            show_progress_bar=False
        )
        return embeddings.astype('float32')
    
    def build_index(self, texts: List[str], labels: List[str], 
                    metadata: List[dict] = None):
        """
        æ„å»ºå‘é‡ç´¢å¼•
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            labels: æ ‡ç­¾åˆ—è¡¨ ('normal' or 'attack')
            metadata: å…ƒæ•°æ®åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        """
        if len(texts) != len(labels):
            raise ValueError("æ–‡æœ¬æ•°é‡ä¸æ ‡ç­¾æ•°é‡ä¸åŒ¹é…")
        
        # 1. æ–‡æœ¬å‘é‡åŒ–
        embeddings = self.encode(texts)
        
        # 2. âœ¨ ä½¿ç”¨å†…ç§¯ç´¢å¼•ï¼ˆå¯¹å½’ä¸€åŒ–å‘é‡ç­‰ä»·äºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        self.index = faiss.IndexFlatIP(self.dimension)
        #                  ^^^^^^^^
        #                  å†…ç§¯ç´¢å¼•ï¼ˆInner Productï¼‰
        
        # 3. æ·»åŠ å‘é‡åˆ°ç´¢å¼•
        self.index.add(embeddings)
        
        # 4. ä¿å­˜å…ƒæ•°æ®
        self.metadata = [
            {
                'url': texts[i],
                'label': labels[i],
                'metadata': metadata[i] if metadata else {}
            }
            for i in range(len(texts))
        ]
        
        print(f"âœ… æˆåŠŸæ·»åŠ  {len(texts)} æ¡å‘é‡")
    
    def search(self, query_text: str, top_k: int = 5) -> List[Tuple[int, float]]:
        """
        æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æœ¬ï¼ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›å‰kä¸ªç»“æœ
            
        Returns:
            List[Tuple[int, float]]: [(ç´¢å¼•, ä½™å¼¦ç›¸ä¼¼åº¦), ...]
                                     ä½™å¼¦ç›¸ä¼¼åº¦èŒƒå›´: [0, 1]
        """
        if self.index is None:
            raise ValueError("å‘é‡åº“æœªåˆå§‹åŒ–")
        
        # 1. æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–ï¼ˆå½’ä¸€åŒ–ï¼‰
        query_vector = self.encode([query_text])
        
        # 2. âœ¨ FAISS æ£€ç´¢ï¼ˆè¿”å›å†…ç§¯ = ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        similarities, indices = self.index.search(query_vector, top_k)
        #   ^^^^^^^^^^^^  
        #   å†…ç§¯åˆ†æ•°ï¼ˆå¯¹å½’ä¸€åŒ–å‘é‡ = ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        
        # 3. è¿”å›ç»“æœ
        results = []
        for idx, sim in zip(indices[0], similarities[0]):
            if idx != -1:  # FAISS ç”¨ -1 è¡¨ç¤ºæ— æ•ˆç»“æœ
                # âœ… ä½™å¼¦ç›¸ä¼¼åº¦å·²ç»åœ¨ [0, 1] èŒƒå›´å†…ï¼Œæ— éœ€è½¬æ¢
                results.append((int(idx), float(sim)))
        
        return results
    
    def save(self, index_path: str, metadata_path: str):
        """ä¿å­˜å‘é‡åº“å’Œå…ƒæ•°æ®"""
        if self.index is None:
            raise ValueError("å‘é‡åº“æœªåˆå§‹åŒ–")
        
        # ä¿å­˜FAISSç´¢å¼•
        faiss.write_index(self.index, index_path)
        
        # ä¿å­˜å…ƒæ•°æ®
        with open(metadata_path, 'wb') as f:
            pickle.dump(self.metadata, f)
        
        print(f"ğŸ’¾ å‘é‡åº“å·²ä¿å­˜:")
        print(f"   ç´¢å¼•: {index_path}")
        print(f"   å…ƒæ•°æ®: {metadata_path}")
    
    def load(self, index_path: str, metadata_path: str):
        """åŠ è½½å‘é‡åº“å’Œå…ƒæ•°æ®"""
        # åŠ è½½FAISSç´¢å¼•
        self.index = faiss.read_index(index_path)
        
        # åŠ è½½å…ƒæ•°æ®
        with open(metadata_path, 'rb') as f:
            self.metadata = pickle.load(f)
        
        print(f"âœ… æˆåŠŸåŠ è½½å‘é‡åº“: {len(self.metadata)} æ¡è®°å½•")