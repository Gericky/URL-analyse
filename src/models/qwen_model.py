"""
Qwenæ¨¡å‹å°è£… - æ”¯æŒLoRAå¾®è°ƒ
"""
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
from time import perf_counter
import os


class QwenModel:
    def __init__(self, model_path: str, config: dict, dtype: str = "float16"):
        """
        åˆå§‹åŒ–Qwenæ¨¡å‹
        
        Args:
            model_path: åŸºç¡€æ¨¡å‹è·¯å¾„
            config: å®Œæ•´é…ç½®å­—å…¸
            dtype: æ•°æ®ç±»å‹ ("float16" æˆ– "float32")
        """
        print(f"ğŸš€ æ­£åœ¨ä»æœ¬åœ°åŠ è½½ Qwen æ¨¡å‹: {model_path}...")
        
        self.config = config
        self.model_path = model_path
        
        # âœ¨ è°ƒè¯•æ¨¡å¼å¼€å…³
        self.debug = config.get('debug', False)
        
        # åŠ è½½tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_path, 
            trust_remote_code=True,
            local_files_only=True
        )
        
        # ç¡®å®šæ•°æ®ç±»å‹
        dtype_mapping = {"float16": torch.float16, "float32": torch.float32}
        self.dtype = dtype_mapping.get(dtype, torch.float16)
        
        # ========== åŠ è½½åŸºç¡€æ¨¡å‹ ==========
        print(f"ğŸ”„ åŠ è½½åŸºç¡€æ¨¡å‹...")
        self.base_model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=self.dtype,
            device_map="auto",
            trust_remote_code=True,
            local_files_only=True
        )
        print(f"âœ… åŸºç¡€æ¨¡å‹å·²åŠ è½½åˆ°è®¾å¤‡: {self.base_model.device}")
        
        # ========== åŠ è½½LoRAå¾®è°ƒæ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰==========
        self.lora_model = None
        self.lora_enabled = config.get('model', {}).get('lora', {}).get('enabled', False)
        
        if self.lora_enabled:
            self._load_lora_adapter()
        
        # ========== åŠ è½½æç¤ºè¯æ¨¡æ¿ ==========
        self._load_prompts()
        
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n")
    
    def _load_lora_adapter(self):
        """åŠ è½½LoRA adapteræƒé‡"""
        lora_config = self.config['model']['lora']
        adapter_path = lora_config['adapter_path']
        checkpoint = lora_config.get('checkpoint', '')
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        if checkpoint:
            full_path = os.path.join(adapter_path, checkpoint)
            if not os.path.exists(full_path):
                print(f"âš ï¸  æŒ‡å®šçš„checkpointä¸å­˜åœ¨: {full_path}")
                print(f"   å›é€€åˆ°ä¸»adapterè·¯å¾„: {adapter_path}")
                full_path = adapter_path
        else:
            full_path = adapter_path
        
        # éªŒè¯è·¯å¾„
        if not os.path.exists(full_path):
            print(f"âŒ LoRA adapterè·¯å¾„ä¸å­˜åœ¨: {full_path}")
            print(f"   å°†ä½¿ç”¨åŸå§‹åŸºç¡€æ¨¡å‹")
            self.lora_enabled = False
            return
        
        print(f"ğŸ”„ åŠ è½½LoRA adapter: {full_path}")
        
        try:
            self.lora_model = PeftModel.from_pretrained(
                self.base_model,
                full_path,
                local_files_only=True
            )
            self.lora_model.eval()
            print(f"âœ… LoRA adapteråŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ LoRA adapteråŠ è½½å¤±è´¥: {e}")
            print(f"   å°†ä½¿ç”¨åŸå§‹åŸºç¡€æ¨¡å‹")
            self.lora_enabled = False
    
    def _load_prompts(self):
        """ä»é…ç½®æ–‡ä»¶æŒ‡å®šçš„è·¯å¾„åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        # åŠ è½½å¿«é€Ÿæ£€æµ‹æç¤ºè¯
        fast_prompt_path = self.config['model']['fast_detection'].get('prompt', '')
        if fast_prompt_path and os.path.exists(fast_prompt_path):
            with open(fast_prompt_path, 'r', encoding='utf-8') as f:
                self.fast_detection_prompt = f.read().strip()
            print(f"âœ… å·²åŠ è½½å¿«é€Ÿæ£€æµ‹æç¤ºè¯: {fast_prompt_path}")
        else:
            self.fast_detection_prompt = self._get_default_fast_prompt()
            print(f"âš ï¸  å¿«é€Ÿæ£€æµ‹æç¤ºè¯æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
        
        # åŠ è½½æ·±åº¦åˆ†ææç¤ºè¯
        deep_prompt_path = self.config['model']['deep_analysis'].get('prompt', '')
        if deep_prompt_path and os.path.exists(deep_prompt_path):
            with open(deep_prompt_path, 'r', encoding='utf-8') as f:
                self.deep_analysis_prompt = f.read().strip()
            print(f"âœ… å·²åŠ è½½æ·±åº¦åˆ†ææç¤ºè¯: {deep_prompt_path}")
        else:
            self.deep_analysis_prompt = self._get_default_deep_prompt()
            print(f"âš ï¸  æ·±åº¦åˆ†ææç¤ºè¯æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
    
    def _get_default_fast_prompt(self) -> str:
        """é»˜è®¤çš„å¿«é€Ÿæ£€æµ‹æç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªURLå®‰å…¨å¿«é€Ÿæ£€æµ‹ç³»ç»Ÿã€‚
ä»»åŠ¡ï¼šå¿«é€Ÿåˆ¤æ–­URLæ˜¯å¦ä¸ºæ”»å‡»ï¼Œåªè¾“å‡ºåˆ¤å®šç»“æœã€‚
è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
- å¦‚æœæ˜¯æ­£å¸¸URLï¼Œè¾“å‡ºï¼š0
- å¦‚æœæ˜¯æ”»å‡»URLï¼Œè¾“å‡ºï¼š1|æ”»å‡»ç±»å‹
æ”»å‡»ç±»å‹åŒ…æ‹¬ï¼šsql_injection, xss, command_injection, path_traversal, file_inclusion, DDoS, malicious_file_access
ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šï¼Œåªè¾“å‡ºåˆ¤å®šç»“æœã€‚"""
    
    def _get_default_deep_prompt(self) -> str:
        """é»˜è®¤çš„æ·±åº¦åˆ†ææç¤ºè¯"""
        return """ä½ æ˜¯ä¸€åé«˜çº§ç½‘ç»œå®‰å…¨åˆ†æå¼•æ“ï¼Œè´Ÿè´£å¯¹å¯ç–‘URLè¿›è¡Œæ·±åº¦å¨èƒåˆ†æã€‚
è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
1. æ”»å‡»ç±»å‹ï¼š[å…·ä½“ç±»å‹]
2. ç®€è¦æ¦‚è¿°ï¼š[ä¸€å¥è¯æ¦‚æ‹¬]
3. è¡Œä¸ºæè¿°ï¼š[è¯¦ç»†æè¿°æ”»å‡»è¡Œä¸º]
4. æˆå› åˆ†æï¼š[åˆ†æä¸ºä½•åˆ¤å®šä¸ºæ”»å‡»]
5. åˆ¤å®šä¾æ®ï¼š[åˆ—å‡ºå…³é”®ç‰¹å¾]
6. é£é™©è¯„ä¼°ï¼š[è¯„ä¼°å±å®³ç¨‹åº¦]
7. é˜²æŠ¤å»ºè®®ï¼š[ç»™å‡ºé˜²æŠ¤æªæ–½]"""
    
    def _select_model(self, stage: str):
        """
        æ ¹æ®é˜¶æ®µå’Œé…ç½®é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹
        
        Args:
            stage: "fast_detection" æˆ– "deep_analysis"
            
        Returns:
            é€‰ä¸­çš„æ¨¡å‹å®ä¾‹
        """
        stage_config = self.config['model'][stage]
        use_lora = stage_config.get('use_lora', False)
        
        # å¦‚æœé…ç½®è¦æ±‚ä½¿ç”¨LoRAä¸”LoRAæ¨¡å‹å·²åŠ è½½ï¼Œåˆ™ä½¿ç”¨LoRAæ¨¡å‹
        if use_lora and self.lora_model is not None:
            return self.lora_model
        else:
            return self.base_model
    
    def fast_detect(self, url: str, similar_cases=None) -> dict:
        """
        ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿæ£€æµ‹æ¨¡å¼
        
        Args:
            url: å¾…æ£€æµ‹URL
            similar_cases: RAGæ£€ç´¢çš„ç›¸ä¼¼æ¡ˆä¾‹åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            åŒ…å«responseå’Œelapsed_timeçš„å­—å…¸
        """
        stage_config = self.config['model']['fast_detection']
        max_new_tokens = stage_config.get('max_new_tokens', 50)
        temperature = stage_config.get('temperature', 0.0)
        use_lora = stage_config.get('use_lora', False)
        
        # ========== é€‰æ‹©æ¨¡å‹ ==========
        model = self._select_model('fast_detection')
        
        # ========== æ„å»ºprompt ==========
        if use_lora and model == self.lora_model:
            prompt = self._build_lora_fast_prompt(url, similar_cases)
            text = prompt
        else:
            # ä½¿ç”¨åŸå§‹chatæ ¼å¼
            user_prompt = f"URL: {url}\nåˆ¤å®šç»“æœï¼š"
            
            if similar_cases:
                rag_context = "\n\nå‚è€ƒç›¸ä¼¼æ¡ˆä¾‹:\n"
                for i, case in enumerate(similar_cases[:3], 1):
                    label_cn = "æ”»å‡»" if case['label'] == 'attack' else "æ­£å¸¸"
                    rag_context += f"{i}. {label_cn} (ç›¸ä¼¼åº¦ {case['similarity_score']:.1%}): {case['url'][:60]}...\n"
                user_prompt = rag_context + "\n" + user_prompt
            
            messages = [
                {"role": "system", "content": self.fast_detection_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            text = self.tokenizer.apply_chat_template(
                messages, 
                tokenize=False, 
                add_generation_prompt=True,
                enable_thinking=False
            )
        
        # âœ¨ è°ƒè¯•è¾“å‡ºï¼ˆä»…åœ¨debugæ¨¡å¼ï¼‰
        if self.debug:
            self._print_debug_fast(url, model, use_lora, text)
        
        # ========== ç”Ÿæˆ ==========
        result = self._generate(model, text, max_new_tokens, temperature, url)
        
        # âœ¨ è°ƒè¯•è¾“å‡ºç»“æœï¼ˆä»…åœ¨debugæ¨¡å¼ï¼‰
        if self.debug:
            self._print_debug_result(result)
        
        return result
    
    def deep_analyze(self, url: str, attack_type: str, similar_cases=None) -> dict:
        """
        ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦åˆ†ææ¨¡å¼
        
        Args:
            url: å¾…åˆ†æURL
            attack_type: ç¬¬ä¸€é˜¶æ®µè¯†åˆ«çš„æ”»å‡»ç±»å‹
            similar_cases: RAGæ£€ç´¢çš„ç›¸ä¼¼æ¡ˆä¾‹åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            åŒ…å«responseå’Œelapsed_timeçš„å­—å…¸
        """
        stage_config = self.config['model']['deep_analysis']
        max_new_tokens = stage_config.get('max_new_tokens', 512)
        temperature = stage_config.get('temperature', 0.3)
        use_lora = stage_config.get('use_lora', False)
        
        # ========== é€‰æ‹©æ¨¡å‹ ==========
        model = self._select_model('deep_analysis')
        
        # ========== æ„å»ºprompt ==========
        if use_lora and model == self.lora_model:
            prompt = self._build_lora_deep_prompt(url, attack_type, similar_cases)
            text = prompt
        else:
            user_prompt = f"""è¯·å¯¹ä»¥ä¸‹URLè¿›è¡Œæ·±åº¦å®‰å…¨åˆ†æï¼š

URL: {url}
åˆæ­¥åˆ¤å®š: {attack_type}"""
            
            if similar_cases:
                rag_context = "\n\n### å‚è€ƒç›¸ä¼¼æ¡ˆä¾‹:\n"
                for i, case in enumerate(similar_cases[:5], 1):
                    label_cn = "æ”»å‡»" if case['label'] == 'attack' else "æ­£å¸¸"
                    rag_context += f"\n**æ¡ˆä¾‹{i}** (ç›¸ä¼¼åº¦: {case['similarity_score']:.2%})\n"
                    rag_context += f"- URL: `{case['url'][:80]}{'...' if len(case['url']) > 80 else ''}`\n"
                    rag_context += f"- ç±»å‹: {label_cn}\n"
                user_prompt = user_prompt + rag_context + "\n\n### åˆ†æä»»åŠ¡\nåŸºäºä»¥ä¸Šç›¸ä¼¼æ¡ˆä¾‹å’Œä½ çš„çŸ¥è¯†ï¼Œè¯·å¯¹ç›®æ ‡URLè¿›è¡Œæ·±åº¦åˆ†æã€‚"
            
            messages = [
                {"role": "system", "content": self.deep_analysis_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            text = self.tokenizer.apply_chat_template(
                messages, 
                tokenize=False, 
                add_generation_prompt=True,
                enable_thinking=False
            )
        
        # âœ¨ è°ƒè¯•è¾“å‡ºï¼ˆä»…åœ¨debugæ¨¡å¼ï¼‰
        if self.debug:
            self._print_debug_deep(url, attack_type, model, use_lora, text)
        
        # ========== ç”Ÿæˆ ==========
        result = self._generate(model, text, max_new_tokens, temperature, url)
        
        # âœ¨ è°ƒè¯•è¾“å‡ºç»“æœï¼ˆä»…åœ¨debugæ¨¡å¼ï¼‰
        if self.debug:
            self._print_debug_result(result)
        
        return result
    
    def _build_lora_fast_prompt(self, url: str, similar_cases=None) -> str:
        """æ„å»ºLoRAå¾®è°ƒæ¨¡å‹çš„å¿«é€Ÿæ£€æµ‹promptï¼ˆæŒ‡ä»¤æ ¼å¼ï¼‰"""
        system_content = """ä½ æ˜¯ä¸€ä¸ªURLå®‰å…¨æ£€æµ‹ç³»ç»Ÿ,ä¸“é—¨è¯†åˆ«æ¶æ„URLã€‚è¯·åˆ¤æ–­ç»™å®šURLæ˜¯å¦å­˜åœ¨å¨èƒã€‚
è¾“å‡ºæ ¼å¼è¦æ±‚: 
- å¦‚æœURLå®‰å…¨,è¾“å‡º: 0|benign
- å¦‚æœURLå­˜åœ¨å¨èƒ,è¾“å‡º: 1|å¨èƒç±»å‹ (å¦‚ phishing, malware, sql_injection, xss, command_injection ç­‰)"""
        
        if similar_cases:
            rag_context = "\n\nå‚è€ƒæ¡ˆä¾‹:\n"
            for i, case in enumerate(similar_cases[:3], 1):
                label_cn = "å¨èƒ" if case['label'] == 'attack' else "å®‰å…¨"
                rag_context += f"{i}. {label_cn} (ç›¸ä¼¼åº¦ {case['similarity_score']:.1%}): {case['url'][:60]}...\n"
            system_content += rag_context
        
        prompt = f"""<|im_start|>system
{system_content}
<|im_end|>
<|im_start|>user
åˆ¤æ–­ä»¥ä¸‹URLæ˜¯å¦å­˜åœ¨å®‰å…¨å¨èƒ
è¾“å…¥URL: {url}<|im_end|>
<|im_start|>assistant
"""
        return prompt
    
    def _build_lora_deep_prompt(self, url: str, attack_type: str, similar_cases=None) -> str:
        """æ„å»ºLoRAå¾®è°ƒæ¨¡å‹çš„æ·±åº¦åˆ†æprompt"""
        system_content = f"""ä½ æ˜¯ä¸€ä¸ªURLå®‰å…¨åˆ†æç³»ç»Ÿã€‚è¯·å¯¹æ£€æµ‹åˆ°çš„å¨èƒURLè¿›è¡Œè¯¦ç»†åˆ†æã€‚

åˆæ­¥åˆ¤å®š: {attack_type}"""
        
        if similar_cases:
            rag_context = "\n\nå‚è€ƒæ¡ˆä¾‹:\n"
            for i, case in enumerate(similar_cases[:5], 1):
                label_cn = "å¨èƒ" if case['label'] == 'attack' else "å®‰å…¨"
                rag_context += f"{i}. {label_cn}: {case['url'][:60]}...\n"
            system_content += rag_context
        
        prompt = f"""<|im_start|>system
{system_content}
<|im_end|>
<|im_start|>user
è¯·è¯¦ç»†åˆ†æä»¥ä¸‹URLçš„å¨èƒæƒ…å†µ:
{url}<|im_end|>
<|im_start|>assistant
"""
        return prompt
    
    def _generate(self, model, text: str, max_new_tokens: int, temperature: float, url: str) -> dict:
        """å†…éƒ¨ç”Ÿæˆæ–¹æ³•"""
        inputs = self.tokenizer([text], return_tensors="pt").to(model.device)
        
        start_time = perf_counter()
        
        with torch.no_grad():
            if temperature > 0:
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    do_sample=True,
                    temperature=temperature,
                    top_p=0.9,
                    top_k=50,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            else:
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    do_sample=False,
                    pad_token_id=self.tokenizer.eos_token_id
                )
        
        elapsed_time = perf_counter() - start_time
        
        response = self.tokenizer.decode(
            outputs[0][inputs.input_ids.shape[1]:], 
            skip_special_tokens=True
        ).strip()
        
        return {
            'url': url,
            'response': response,
            'elapsed_time': elapsed_time
        }
    
    # ========== è°ƒè¯•è¾“å‡ºæ–¹æ³•ï¼ˆä»…åœ¨debug=trueæ—¶è°ƒç”¨ï¼‰==========
    
    def _print_debug_fast(self, url: str, model, use_lora: bool, text: str):
        """æ‰“å°å¿«é€Ÿæ£€æµ‹çš„è°ƒè¯•ä¿¡æ¯"""
        print("\n" + "="*80)
        print("ğŸ” ã€è°ƒè¯•ã€‘å¿«é€Ÿæ£€æµ‹é˜¶æ®µ")
        print("="*80)
        print(f"ğŸ“Œ URL: {url[:100]}{'...' if len(url) > 100 else ''}")
        print(f"ğŸ¤– æ¨¡å‹: {'LoRAå¾®è°ƒæ¨¡å‹' if (use_lora and model == self.lora_model) else 'åŸå§‹åŸºç¡€æ¨¡å‹'}")
        print("\n" + "-"*80)
        print("ğŸ“ å®Œæ•´è¾“å…¥Prompt:")
        print("-"*80)
        print(text)
        print("-"*80)
    
    def _print_debug_deep(self, url: str, attack_type: str, model, use_lora: bool, text: str):
        """æ‰“å°æ·±åº¦åˆ†æçš„è°ƒè¯•ä¿¡æ¯"""
        print("\n" + "="*80)
        print("ğŸ” ã€è°ƒè¯•ã€‘æ·±åº¦åˆ†æé˜¶æ®µ")
        print("="*80)
        print(f"ğŸ“Œ URL: {url[:100]}{'...' if len(url) > 100 else ''}")
        print(f"ğŸ¯ åˆæ­¥åˆ¤å®š: {attack_type}")
        print(f"ğŸ¤– æ¨¡å‹: {'LoRAå¾®è°ƒæ¨¡å‹' if (use_lora and model == self.lora_model) else 'åŸå§‹åŸºç¡€æ¨¡å‹'}")
        print("\n" + "-"*80)
        print("ğŸ“ å®Œæ•´è¾“å…¥Prompt:")
        print("-"*80)
        print(text)
        print("-"*80)
    
    def _print_debug_result(self, result: dict):
        """æ‰“å°æ¨¡å‹è¾“å‡ºç»“æœ"""
        print("\n" + "-"*80)
        print("ğŸ¯ æ¨¡å‹åŸå§‹è¾“å‡º:")
        print("-"*80)
        print(result['response'])
        print("-"*80)
        print(f"â±ï¸  è€—æ—¶: {result['elapsed_time']:.3f}ç§’")
        print("="*80 + "\n")
    
    def get_model_info(self, stage: str = "fast_detection") -> dict:
        """è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯"""
        stage_config = self.config['model'][stage]
        use_lora = stage_config.get('use_lora', False)
        
        info = {
            'base_model': self.model_path,
            'lora_enabled': self.lora_enabled,
            'stage': stage,
            'using_lora': use_lora and self.lora_model is not None,
            'generation_config': {
                'max_new_tokens': stage_config.get('max_new_tokens'),
                'temperature': stage_config.get('temperature')
            }
        }
        
        if self.lora_enabled:
            lora_config = self.config['model']['lora']
            info['lora_adapter'] = lora_config['adapter_path']
            if lora_config.get('checkpoint'):
                info['checkpoint'] = lora_config['checkpoint']
        
        return info