"""
ç»“æœç»Ÿè®¡åˆ†ææ¨¡å— - è´Ÿè´£ç¬¬ä¸€é˜¶æ®µå’Œç¬¬äºŒé˜¶æ®µæ£€æµ‹ç»“æœçš„ç»Ÿè®¡å’Œè¯„ä¼°
"""
import json
import os
from typing import List, Dict
from time import perf_counter
class ResultStatistics:
    """ç»“æœç»Ÿè®¡åˆ†æå™¨"""
    
    def __init__(self, all_results: List[Dict], output_config: Dict):
        """
        åˆå§‹åŒ–ç»Ÿè®¡åˆ†æå™¨
        
        Args:
            all_results: æ‰€æœ‰æ£€æµ‹ç»“æœåˆ—è¡¨
            output_config: è¾“å‡ºé…ç½®å­—å…¸
        """
        self.all_results = all_results
        self.output_config = output_config
        self.output_dir = output_config['dir']
        
        # åˆ†ç±»ç»“æœ
        self.normal_results = [r for r in all_results if r['predicted'] == "0"]
        self.anomalous_results = [r for r in all_results if r['predicted'] == "1"]
        
        # æŒ‰çœŸå®æ ‡ç­¾åˆ†ç±»
        self.true_normal_results = [r for r in all_results if r['true_label'] == "0"]
        self.true_attack_results = [r for r in all_results if r['true_label'] == "1"]
        
        # æ··æ·†çŸ©é˜µ
        self.tp = sum(1 for r in all_results if r['true_label'] == "1" and r['predicted'] == "1")
        self.tn = sum(1 for r in all_results if r['true_label'] == "0" and r['predicted'] == "0")
        self.fp = sum(1 for r in all_results if r['true_label'] == "0" and r['predicted'] == "1")
        self.fn = sum(1 for r in all_results if r['true_label'] == "1" and r['predicted'] == "0")
        
        # æ£€æµ‹æ–¹æ³•ç»Ÿè®¡
        self.rule_normal_count = sum(1 for r in all_results if r.get('detection_method') == 'rule_normal')
        self.rule_anomalous_count = sum(1 for r in all_results if r.get('detection_method') == 'rule_anomalous')
        self.model_count = sum(1 for r in all_results if r.get('detection_method') == 'model')
        
        # æŒ‰æ£€æµ‹æ–¹æ³•åˆ†ç±»ç»“æœ
        self.rule_results = [r for r in all_results if r.get('detection_method') in ['rule_normal', 'rule_anomalous']]
        self.model_results = [r for r in all_results if r.get('detection_method') == 'model']
        
        # æ•°æ®é›† + æ£€æµ‹æ–¹æ³•äº¤å‰ç»Ÿè®¡
        # æ­£å¸¸æ•°æ®é›† (true_label == "0")
        self.normal_by_rule = [r for r in self.true_normal_results if r.get('detection_method') in ['rule_normal', 'rule_anomalous']]
        self.normal_by_model = [r for r in self.true_normal_results if r.get('detection_method') == 'model']
        
        # æ”»å‡»æ•°æ®é›† (true_label == "1")
        self.attack_by_rule = [r for r in self.true_attack_results if r.get('detection_method') in ['rule_normal', 'rule_anomalous']]
        self.attack_by_model = [r for r in self.true_attack_results if r.get('detection_method') == 'model']
        
        # é”™è¯¯åˆ†æ
        self.fp_results = [r for r in all_results if r['true_label'] == "0" and r['predicted'] == "1"]
        self.fn_results = [r for r in all_results if r['true_label'] == "1" and r['predicted'] == "0"]
        # âœ¨ æ–°å¢ï¼šæ—¶é•¿ç»Ÿè®¡
        self.rule_normal_time = sum(r.get('elapsed_time_sec', 0) for r in all_results if r.get('detection_method') == 'rule_normal')
        self.rule_anomalous_time = sum(r.get('elapsed_time_sec', 0) for r in all_results if r.get('detection_method') == 'rule_anomalous')
        self.model_time = sum(r.get('elapsed_time_sec', 0) for r in all_results if r.get('detection_method') == 'model')
        
        self.total_rule_time = self.rule_normal_time + self.rule_anomalous_time
        self.total_model_time = self.model_time
    
    def print_stage1_basic_statistics(self, elapsed_time: float):
        """
        æ‰“å°ç¬¬ä¸€é˜¶æ®µåŸºç¡€ç»Ÿè®¡
        
        Args:
            elapsed_time: ç¬¬ä¸€é˜¶æ®µç”¨æ—¶ï¼ˆç§’ï¼‰
        """
        total = len(self.all_results)
        if total == 0:
            print(f"\n{'='*60}")
            print(f"âš ï¸  è­¦å‘Šï¼šæ²¡æœ‰æ£€æµ‹ç»“æœ")
            print(f"{'='*60}\n")
            return
        
        # è®¡ç®—å®é™…æ£€æµ‹æ€»è€—æ—¶ï¼ˆè§„åˆ™ + æ¨¡å‹ï¼‰
        actual_detection_time = self.total_rule_time + self.total_model_time
        overhead_time = elapsed_time - actual_detection_time
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ç¬¬ä¸€é˜¶æ®µåŸºç¡€ç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"â±ï¸  æ€»è¿è¡Œæ—¶é—´: {elapsed_time:.2f} ç§’")
        print(f"   â”œâ”€ å®é™…æ£€æµ‹è€—æ—¶: {actual_detection_time:.4f} ç§’ ({actual_detection_time/elapsed_time*100:.1f}%)")
        print(f"   â”‚  â”œâ”€ è§„åˆ™æ£€æµ‹: {self.total_rule_time:.4f} ç§’")
        print(f"   â”‚  â””â”€ æ¨¡å‹æ£€æµ‹: {self.total_model_time:.4f} ç§’")
        print(f"   â””â”€ å…¶ä»–å¼€é”€: {overhead_time:.4f} ç§’ ({overhead_time/elapsed_time*100:.1f}%)")
        print(f"      (æ–‡ä»¶I/Oã€æ•°æ®å¤„ç†ç­‰)")
        print()
        print(f"ğŸ“Š æ€»URLæ•°: {total}")
        print(f"   å¹³å‡æ¯URLæ€»è€—æ—¶: {elapsed_time/total*1000:.2f} æ¯«ç§’")
        print(f"   å¹³å‡æ¯URLæ£€æµ‹è€—æ—¶: {actual_detection_time/total*1000:.2f} æ¯«ç§’")
        print()
        print(f"ğŸ“‚ è¾“å…¥æ•°æ®é›†:")
        print(f"   æ­£å¸¸URLæ•°æ®é›†: {len(self.true_normal_results)} æ¡")
        print(f"   æ”»å‡»URLæ•°æ®é›†: {len(self.true_attack_results)} æ¡")
        print()
        print(f"ğŸ¯ æ£€æµ‹ç»“æœ:")
        print(f"   åˆ¤å®šä¸ºæ­£å¸¸: {len(self.normal_results)} æ¡")
        print(f"   åˆ¤å®šä¸ºå¼‚å¸¸: {len(self.anomalous_results)} æ¡")
        print(f"{'='*60}")
    
    def calculate_metrics(self) -> Dict:
        """
        è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        
        Returns:
            dict: åŒ…å«å„é¡¹è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
        """
        total = len(self.all_results)
        
        metrics = {
            'total': total,
            'tp': self.tp,
            'tn': self.tn,
            'fp': self.fp,
            'fn': self.fn,
            'accuracy': 0.0,
            'recall': 0.0,
            'precision': 0.0,
            'f1_score': 0.0,
            'fpr': 0.0,
            'fnr': 0.0
        }
        
        # å‡†ç¡®ç‡
        if total > 0:
            metrics['accuracy'] = (self.tp + self.tn) / total * 100
        
        # å¬å›ç‡
        if (self.tp + self.fn) > 0:
            metrics['recall'] = self.tp / (self.tp + self.fn) * 100
        
        # ç²¾ç¡®ç‡
        if (self.tp + self.fp) > 0:
            metrics['precision'] = self.tp / (self.tp + self.fp) * 100
        
        # F1åˆ†æ•°
        if (metrics['precision'] + metrics['recall']) > 0:
            metrics['f1_score'] = 2 * metrics['precision'] * metrics['recall'] / (metrics['precision'] + metrics['recall'])
        
        # è¯¯æŠ¥ç‡
        if (self.fp + self.tn) > 0:
            metrics['fpr'] = self.fp / (self.fp + self.tn) * 100
        
        # æ¼æŠ¥ç‡
        if (self.fn + self.tp) > 0:
            metrics['fnr'] = self.fn / (self.fn + self.tp) * 100
        
        return metrics
    
    def print_confusion_matrix(self):
        """æ‰“å°æ··æ·†çŸ©é˜µ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ··æ·†çŸ©é˜µ (Confusion Matrix)")
        print("=" * 60)
        print(f"{'':15} | é¢„æµ‹:æ­£å¸¸(0) | é¢„æµ‹:æ”»å‡»(1) | åˆè®¡")
        print("-" * 60)
        print(f"çœŸå®:æ­£å¸¸(0)  |    TN={self.tn:3d}     |    FP={self.fp:3d}     | {self.tn+self.fp:3d}")
        print(f"çœŸå®:æ”»å‡»(1)  |    FN={self.fn:3d}     |    TP={self.tp:3d}     | {self.fn+self.tp:3d}")
        print("-" * 60)
        print(f"åˆè®¡          |      {self.tn+self.fn:3d}      |      {self.fp+self.tp:3d}      | {len(self.all_results):3d}")
        print("=" * 60)
        print("\nè¯´æ˜:")
        print("  TP (True Positive):  æ­£ç¡®è¯†åˆ«ä¸ºæ”»å‡»")
        print("  TN (True Negative):  æ­£ç¡®è¯†åˆ«ä¸ºæ­£å¸¸")
        print("  FP (False Positive): è¯¯æŠ¥ - æ­£å¸¸URLè¢«åˆ¤å®šä¸ºæ”»å‡»")
        print("  FN (False Negative): æ¼æŠ¥ - æ”»å‡»URLè¢«åˆ¤å®šä¸ºæ­£å¸¸")
    
    def print_metrics(self):
        """æ‰“å°è¯„ä¼°æŒ‡æ ‡"""
        metrics = self.calculate_metrics()
        
        print("\n" + "=" * 60)
        print("ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡ (Evaluation Metrics)")
        print("=" * 60)
        print(f"âœ… å‡†ç¡®ç‡ (Accuracy):   {metrics['accuracy']:.2f}%")
        print(f"   = (TP + TN) / Total = ({self.tp} + {self.tn}) / {metrics['total']}")
        print(f"   å«ä¹‰: æ‰€æœ‰é¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹")
        print()
        print(f"ğŸ¯ å¬å›ç‡ (Recall):     {metrics['recall']:.2f}%")
        print(f"   = TP / (TP + FN) = {self.tp} / ({self.tp} + {self.fn})")
        print(f"   å«ä¹‰: åœ¨æ‰€æœ‰çœŸå®æ”»å‡»ä¸­,æˆåŠŸè¯†åˆ«å‡ºçš„æ¯”ä¾‹")
        print(f"   (ä¹Ÿå«çœŸæ­£ç‡ TPR,è¶Šé«˜è¶Šå¥½,è¡¨ç¤ºä¸æ¼æ‰æ”»å‡»)")
        print()
        print(f"ğŸ” ç²¾ç¡®ç‡ (Precision):  {metrics['precision']:.2f}%")
        print(f"   = TP / (TP + FP) = {self.tp} / ({self.tp} + {self.fp})")
        print(f"   å«ä¹‰: åœ¨é¢„æµ‹ä¸ºæ”»å‡»çš„æ ·æœ¬ä¸­,çœŸæ­£æ˜¯æ”»å‡»çš„æ¯”ä¾‹")
        print(f"   (è¶Šé«˜è¶Šå¥½,è¡¨ç¤ºä¸è¯¯æŠ¥æ­£å¸¸URL)")
        print()
        print(f"âš–ï¸  F1åˆ†æ•° (F1-Score):   {metrics['f1_score']:.2f}%")
        print(f"   = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)")
        print(f"   å«ä¹‰: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡,ç»¼åˆè¯„ä»·æŒ‡æ ‡")
        print()
        print(f"âš ï¸  è¯¯æŠ¥ç‡ (FPR):       {metrics['fpr']:.2f}%")
        print(f"   = FP / (FP + TN) = {self.fp} / ({self.fp} + {self.tn})")
        print(f"   å«ä¹‰: æ­£å¸¸URLè¢«è¯¯åˆ¤ä¸ºæ”»å‡»çš„æ¯”ä¾‹ (è¶Šä½è¶Šå¥½)")
        print()
        print(f"âŒ æ¼æŠ¥ç‡ (FNR):       {metrics['fnr']:.2f}%")
        print(f"   = FN / (FN + TP) = {self.fn} / ({self.fn} + {self.tp})")
        print(f"   å«ä¹‰: æ”»å‡»URLè¢«æ¼åˆ¤ä¸ºæ­£å¸¸çš„æ¯”ä¾‹ (è¶Šä½è¶Šå¥½)")
        print("=" * 60)
    
    def print_detection_method_statistics(self):
        """æ‰“å°æ£€æµ‹æ–¹æ³•ç»Ÿè®¡ï¼ˆåŒ…å«æ—¶é•¿ä¿¡æ¯ï¼‰"""
        total = len(self.all_results)
        
        if total == 0:
            print("\n" + "=" * 60)
            print("ğŸ”§ æ£€æµ‹æ–¹æ³•ç»Ÿè®¡")
            print("=" * 60)
            print("âš ï¸  æ²¡æœ‰æ£€æµ‹ç»“æœå¯ä¾›ç»Ÿè®¡")
            print("=" * 60)
            return
        
        print("\n" + "=" * 60)
        print("ğŸ”§ æ£€æµ‹æ–¹æ³•ç»Ÿè®¡ï¼ˆæ•°é‡ + æ—¶é•¿ï¼‰")
        print("=" * 60)
        
        # è§„åˆ™æ£€æµ‹ç»Ÿè®¡
        total_rule_count = self.rule_normal_count + self.rule_anomalous_count
        print(f"\nğŸ” è§„åˆ™å¼•æ“æ£€æµ‹:")
        print(f"   â”œâ”€ æ€»åŒ¹é…æ•°: {total_rule_count} æ¡ ({total_rule_count/total*100:.1f}%)")
        print(f"   â”œâ”€ æ€»è€—æ—¶: {self.total_rule_time:.4f} ç§’")
        
        if total_rule_count > 0:
            avg_rule_time = self.total_rule_time / total_rule_count
            print(f"   â”œâ”€ å¹³å‡è€—æ—¶: {avg_rule_time*1000:.4f} æ¯«ç§’/æ¡")
            print(f"   â”‚")
            print(f"   â”œâ”€ åˆ¤å®šä¸ºæ­£å¸¸: {self.rule_normal_count} æ¡")
            if self.rule_normal_count > 0:
                print(f"   â”‚  â”œâ”€ è€—æ—¶: {self.rule_normal_time:.4f} ç§’")
                print(f"   â”‚  â””â”€ å¹³å‡: {self.rule_normal_time/self.rule_normal_count*1000:.4f} æ¯«ç§’/æ¡")
            print(f"   â”‚")
            print(f"   â””â”€ åˆ¤å®šä¸ºå¼‚å¸¸: {self.rule_anomalous_count} æ¡")
            if self.rule_anomalous_count > 0:
                print(f"      â”œâ”€ è€—æ—¶: {self.rule_anomalous_time:.4f} ç§’")
                print(f"      â””â”€ å¹³å‡: {self.rule_anomalous_time/self.rule_anomalous_count*1000:.4f} æ¯«ç§’/æ¡")
        
        # æ¨¡å‹æ£€æµ‹ç»Ÿè®¡
        print(f"\nğŸ¤– æ¨¡å‹æ¨ç†æ£€æµ‹:")
        print(f"   â”œâ”€ æ£€æµ‹æ•°é‡: {self.model_count} æ¡ ({self.model_count/total*100:.1f}%)")
        print(f"   â”œâ”€ æ€»è€—æ—¶: {self.total_model_time:.4f} ç§’")
        if self.model_count > 0:
            avg_model_time = self.total_model_time / self.model_count
            print(f"   â””â”€ å¹³å‡è€—æ—¶: {avg_model_time*1000:.4f} æ¯«ç§’/æ¡")
        
        # æ•ˆç‡å¯¹æ¯”
        if total_rule_count > 0 and self.model_count > 0:
            avg_rule_time = self.total_rule_time / total_rule_count
            avg_model_time = self.total_model_time / self.model_count
            speedup = avg_model_time / avg_rule_time
            print(f"\nâš¡ æ•ˆç‡å¯¹æ¯”:")
            print(f"   â””â”€ è§„åˆ™æ¯”æ¨¡å‹å¿« {speedup:.2f}x")
        
        # æ•´ä½“ç»Ÿè®¡
        print(f"\nğŸ“Š æ•´ä½“å‘½ä¸­ç‡:")
        print(f"   â”œâ”€ è§„åˆ™å‘½ä¸­ç‡: {total_rule_count/total*100:.1f}%")
        print(f"   â””â”€ æ¨¡å‹è°ƒç”¨ç‡: {self.model_count/total*100:.1f}%")
        
        print("=" * 60)
    
    def print_dataset_method_statistics(self):
        """æ‰“å°æ•°æ®é›† Ã— æ£€æµ‹æ–¹æ³•äº¤å‰ç»Ÿè®¡"""
        print("\n" + "=" * 60)
        print("ğŸ“‚ æ•°æ®é›† Ã— æ£€æµ‹æ–¹æ³•äº¤å‰ç»Ÿè®¡")
        print("=" * 60)
        
        # æ­£å¸¸æ•°æ®é›†ç»Ÿè®¡
        total_normal = len(self.true_normal_results)
        normal_rule_count = len(self.normal_by_rule)
        normal_model_count = len(self.normal_by_model)
        
        # æ­£å¸¸æ•°æ®é›†çš„æ­£ç¡®è¯†åˆ«æ•°
        normal_correct_by_rule = sum(1 for r in self.normal_by_rule if r['predicted'] == "0")
        normal_correct_by_model = sum(1 for r in self.normal_by_model if r['predicted'] == "0")
        
        print(f"\nğŸŸ¢ æ­£å¸¸URLæ•°æ®é›† (å…± {total_normal} æ¡):")
        print(f"   â”œâ”€ è§„åˆ™å¼•æ“å¤„ç†: {normal_rule_count:3d} æ¡ ({normal_rule_count/total_normal*100:.1f}%)")
        if normal_rule_count > 0:
            print(f"   â”‚  â”œâ”€ æ­£ç¡®è¯†åˆ«: {normal_correct_by_rule} æ¡")
            print(f"   â”‚  â”œâ”€ è¯¯æŠ¥(åˆ¤ä¸ºæ”»å‡»): {normal_rule_count - normal_correct_by_rule} æ¡")
            print(f"   â”‚  â””â”€ å‡†ç¡®ç‡: {normal_correct_by_rule/normal_rule_count*100:.2f}%")
        print(f"   â””â”€ æ¨¡å‹æ¨ç†å¤„ç†: {normal_model_count:3d} æ¡ ({normal_model_count/total_normal*100:.1f}%)")
        if normal_model_count > 0:
            print(f"      â”œâ”€ æ­£ç¡®è¯†åˆ«: {normal_correct_by_model} æ¡")
            print(f"      â”œâ”€ è¯¯æŠ¥(åˆ¤ä¸ºæ”»å‡»): {normal_model_count - normal_correct_by_model} æ¡")
            print(f"      â””â”€ å‡†ç¡®ç‡: {normal_correct_by_model/normal_model_count*100:.2f}%")
        
        # æ”»å‡»æ•°æ®é›†ç»Ÿè®¡
        total_attack = len(self.true_attack_results)
        attack_rule_count = len(self.attack_by_rule)
        attack_model_count = len(self.attack_by_model)
        
        # æ”»å‡»æ•°æ®é›†çš„æ­£ç¡®è¯†åˆ«æ•°
        attack_correct_by_rule = sum(1 for r in self.attack_by_rule if r['predicted'] == "1")
        attack_correct_by_model = sum(1 for r in self.attack_by_model if r['predicted'] == "1")
        
        print(f"\nğŸ”´ æ”»å‡»URLæ•°æ®é›† (å…± {total_attack} æ¡):")
        print(f"   â”œâ”€ è§„åˆ™å¼•æ“å¤„ç†: {attack_rule_count:3d} æ¡ ({attack_rule_count/total_attack*100:.1f}%)")
        if attack_rule_count > 0:
            print(f"   â”‚  â”œâ”€ æ­£ç¡®è¯†åˆ«: {attack_correct_by_rule} æ¡")
            print(f"   â”‚  â”œâ”€ æ¼æŠ¥(åˆ¤ä¸ºæ­£å¸¸): {attack_rule_count - attack_correct_by_rule} æ¡")
            print(f"   â”‚  â””â”€ å‡†ç¡®ç‡: {attack_correct_by_rule/attack_rule_count*100:.2f}%")
        print(f"   â””â”€ æ¨¡å‹æ¨ç†å¤„ç†: {attack_model_count:3d} æ¡ ({attack_model_count/total_attack*100:.1f}%)")
        if attack_model_count > 0:
            print(f"      â”œâ”€ æ­£ç¡®è¯†åˆ«: {attack_correct_by_model} æ¡")
            print(f"      â”œâ”€ æ¼æŠ¥(åˆ¤ä¸ºæ­£å¸¸): {attack_model_count - attack_correct_by_model} æ¡")
            print(f"      â””â”€ å‡†ç¡®ç‡: {attack_correct_by_model/attack_model_count*100:.2f}%")
        
        print("=" * 60)
    
    def print_method_performance_comparison(self):
        """æ‰“å°æ£€æµ‹æ–¹æ³•æ€§èƒ½å¯¹æ¯”"""
        print("\n" + "=" * 60)
        print("âš”ï¸  æ£€æµ‹æ–¹æ³•æ€§èƒ½å¯¹æ¯”")
        print("=" * 60)
        
        # è§„åˆ™å¼•æ“æ€§èƒ½
        rule_total = len(self.rule_results)
        if rule_total > 0:
            rule_tp = sum(1 for r in self.rule_results if r['true_label'] == "1" and r['predicted'] == "1")
            rule_tn = sum(1 for r in self.rule_results if r['true_label'] == "0" and r['predicted'] == "0")
            rule_fp = sum(1 for r in self.rule_results if r['true_label'] == "0" and r['predicted'] == "1")
            rule_fn = sum(1 for r in self.rule_results if r['true_label'] == "1" and r['predicted'] == "0")
            
            rule_accuracy = (rule_tp + rule_tn) / rule_total * 100
            rule_fpr = rule_fp / (rule_fp + rule_tn) * 100 if (rule_fp + rule_tn) > 0 else 0
            rule_fnr = rule_fn / (rule_fn + rule_tp) * 100 if (rule_fn + rule_tp) > 0 else 0
            
            print(f"\nğŸ“ è§„åˆ™å¼•æ“ (å¤„ç† {rule_total} æ¡):")
            print(f"   â”œâ”€ å‡†ç¡®ç‡: {rule_accuracy:.2f}%")
            print(f"   â”œâ”€ è¯¯æŠ¥ç‡: {rule_fpr:.2f}% ({rule_fp}/{rule_fp+rule_tn} æ­£å¸¸URLè¢«è¯¯åˆ¤)")
            print(f"   â”œâ”€ æ¼æŠ¥ç‡: {rule_fnr:.2f}% ({rule_fn}/{rule_fn+rule_tp} æ”»å‡»URLè¢«æ¼åˆ¤)")
            print(f"   â””â”€ æ··æ·†çŸ©é˜µ: TP={rule_tp}, TN={rule_tn}, FP={rule_fp}, FN={rule_fn}")
        else:
            print(f"\nğŸ“ è§„åˆ™å¼•æ“: æœªå¤„ç†ä»»ä½•URL")
        
        # æ¨¡å‹æ¨ç†æ€§èƒ½
        model_total = len(self.model_results)
        if model_total > 0:
            model_tp = sum(1 for r in self.model_results if r['true_label'] == "1" and r['predicted'] == "1")
            model_tn = sum(1 for r in self.model_results if r['true_label'] == "0" and r['predicted'] == "0")
            model_fp = sum(1 for r in self.model_results if r['true_label'] == "0" and r['predicted'] == "1")
            model_fn = sum(1 for r in self.model_results if r['true_label'] == "1" and r['predicted'] == "0")
            
            model_accuracy = (model_tp + model_tn) / model_total * 100
            model_fpr = model_fp / (model_fp + model_tn) * 100 if (model_fp + model_tn) > 0 else 0
            model_fnr = model_fn / (model_fn + model_tp) * 100 if (model_fn + model_tp) > 0 else 0
            
            print(f"\nğŸ¤– æ¨¡å‹æ¨ç† (å¤„ç† {model_total} æ¡):")
            print(f"   â”œâ”€ å‡†ç¡®ç‡: {model_accuracy:.2f}%")
            print(f"   â”œâ”€ è¯¯æŠ¥ç‡: {model_fpr:.2f}% ({model_fp}/{model_fp+model_tn} æ­£å¸¸URLè¢«è¯¯åˆ¤)")
            print(f"   â”œâ”€ æ¼æŠ¥ç‡: {model_fnr:.2f}% ({model_fn}/{model_fn+model_tp} æ”»å‡»URLè¢«æ¼åˆ¤)")
            print(f"   â””â”€ æ··æ·†çŸ©é˜µ: TP={model_tp}, TN={model_tn}, FP={model_fp}, FN={model_fn}")
        else:
            print(f"\nğŸ¤– æ¨¡å‹æ¨ç†: æœªå¤„ç†ä»»ä½•URL")
        
        print("=" * 60)
    
    def print_error_analysis(self, max_display: int = 3):
        """
        æ‰“å°é”™è¯¯åˆ†æï¼ˆç»ˆç«¯åªæ˜¾ç¤ºå‰å‡ ä¸ªç¤ºä¾‹ï¼‰
        
        Args:
            max_display: ç»ˆç«¯æ˜¾ç¤ºçš„æœ€å¤§ç¤ºä¾‹æ•°é‡ï¼ˆé»˜è®¤3ä¸ªï¼‰
        """
        print("\n" + "=" * 60)
        print("ğŸ” é”™è¯¯åˆ†æ")
        print("=" * 60)
        
        # è¯¯æŠ¥åˆ†æ (FP)
        print(f"\nâš ï¸  è¯¯æŠ¥ (False Positive) - å…± {len(self.fp_results)} æ¡:")
        if len(self.fp_results) > 0:
            fp_by_rule = [r for r in self.fp_results if r.get('detection_method') in ['rule_normal', 'rule_anomalous']]
            fp_by_model = [r for r in self.fp_results if r.get('detection_method') == 'model']
            
            print(f"   â”œâ”€ è§„åˆ™å¼•æ“è¯¯æŠ¥: {len(fp_by_rule)} æ¡ ({len(fp_by_rule)/len(self.fp_results)*100:.1f}%)")
            print(f"   â””â”€ æ¨¡å‹æ¨ç†è¯¯æŠ¥: {len(fp_by_model)} æ¡ ({len(fp_by_model)/len(self.fp_results)*100:.1f}%)")
            
            # åªæ˜¾ç¤ºå‰å‡ ä¸ªç¤ºä¾‹
            display_count = min(max_display, len(self.fp_results))
            print(f"\n   ç¤ºä¾‹ï¼ˆæ˜¾ç¤ºå‰ {display_count} æ¡ï¼Œå®Œæ•´åˆ—è¡¨è§: stage1_false_positives.jsonï¼‰:")
            for i, result in enumerate(self.fp_results[:display_count], 1):
                url_display = result['url'][:70] + "..." if len(result['url']) > 70 else result['url']
                print(f"   {i}. {url_display}")
                print(f"      æ£€æµ‹æ–¹æ³•: {result.get('detection_method', 'unknown')}")
                if result.get('detection_method') in ['rule_normal', 'rule_anomalous']:
                    matched_rules = result.get('matched_rules', [])
                    if matched_rules:
                        rule_names = [r.get('rule_name', 'unknown') for r in matched_rules]
                        print(f"      åŒ¹é…è§„åˆ™: {', '.join(rule_names)}")
        else:
            print(f"   âœ… æ— è¯¯æŠ¥!")
        
        # æ¼æŠ¥åˆ†æ (FN)
        print(f"\nâŒ æ¼æŠ¥ (False Negative) - å…± {len(self.fn_results)} æ¡:")
        if len(self.fn_results) > 0:
            fn_by_rule = [r for r in self.fn_results if r.get('detection_method') in ['rule_normal', 'rule_anomalous']]
            fn_by_model = [r for r in self.fn_results if r.get('detection_method') == 'model']
            
            print(f"   â”œâ”€ è§„åˆ™å¼•æ“æ¼æŠ¥: {len(fn_by_rule)} æ¡ ({len(fn_by_rule)/len(self.fn_results)*100:.1f}%)")
            print(f"   â””â”€ æ¨¡å‹æ¨ç†æ¼æŠ¥: {len(fn_by_model)} æ¡ ({len(fn_by_model)/len(self.fn_results)*100:.1f}%)")
            
            # åªæ˜¾ç¤ºå‰å‡ ä¸ªç¤ºä¾‹
            display_count = min(max_display, len(self.fn_results))
            print(f"\n   ç¤ºä¾‹ï¼ˆæ˜¾ç¤ºå‰ {display_count} æ¡ï¼Œå®Œæ•´åˆ—è¡¨è§: stage1_false_negatives.jsonï¼‰:")
            for i, result in enumerate(self.fn_results[:display_count], 1):
                url_display = result['url'][:70] + "..." if len(result['url']) > 70 else result['url']
                print(f"   {i}. {url_display}")
                print(f"      æ£€æµ‹æ–¹æ³•: {result.get('detection_method', 'unknown')}")
                if result.get('detection_method') in ['rule_normal', 'rule_anomalous']:
                    matched_rules = result.get('matched_rules', [])
                    if matched_rules:
                        rule_names = [r.get('rule_name', 'unknown') for r in matched_rules]
                        print(f"      åŒ¹é…è§„åˆ™: {', '.join(rule_names)}")
        else:
            print(f"   âœ… æ— æ¼æŠ¥!")
        
        print("=" * 60)
    
    def print_attack_type_distribution(self):
        """æ‰“å°æ”»å‡»ç±»å‹åˆ†å¸ƒ"""
        if not self.anomalous_results:
            return
        
        attack_types = {}
        for result in self.anomalous_results:
            attack_type = result.get('attack_type', 'unknown')
            attack_types[attack_type] = attack_types.get(attack_type, 0) + 1
        
        print("\n" + "=" * 60)
        print("ğŸ¯ å¼‚å¸¸URLæ”»å‡»ç±»å‹åˆ†å¸ƒ")
        print("=" * 60)
        total_anomalous = len(self.anomalous_results)
        for attack_type, count in sorted(attack_types.items(), key=lambda x: x[1], reverse=True):
            percentage = count / total_anomalous * 100
            print(f"  {attack_type:20s}: {count:3d} æ¡ ({percentage:.1f}%)")
        print("=" * 60)
    
    def save_results(self):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ä¿å­˜ç¬¬ä¸€é˜¶æ®µæ‰€æœ‰ç»“æœ
        stage1_all_file = os.path.join(
            self.output_dir, 
            self.output_config.get('stage1_all', 'stage1_realtime_all.json')
        )
        with open(stage1_all_file, 'w', encoding='utf-8') as f:
            json.dump(self.all_results, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
        metrics = self.calculate_metrics()
        
        # âœ¨ æ–°å¢ï¼šæ—¶é•¿ç»Ÿè®¡ä¿¡æ¯
        total_rule_count = self.rule_normal_count + self.rule_anomalous_count
        
        # æ‰©å±•æŒ‡æ ‡ï¼šæ·»åŠ æ—¶é•¿ç»Ÿè®¡
        extended_metrics = {
            **metrics,
            'timing_statistics': {  # âœ¨ æ–°å¢éƒ¨åˆ†
                'rule_engine': {
                    'total_count': total_rule_count,
                    'total_time_sec': round(self.total_rule_time, 6),
                    'avg_time_sec': round(self.total_rule_time / total_rule_count, 6) if total_rule_count > 0 else 0,
                    'avg_time_ms': round(self.total_rule_time / total_rule_count * 1000, 4) if total_rule_count > 0 else 0,
                    'normal_rules': {
                        'count': self.rule_normal_count,
                        'total_time_sec': round(self.rule_normal_time, 6),
                        'avg_time_ms': round(self.rule_normal_time / self.rule_normal_count * 1000, 4) if self.rule_normal_count > 0 else 0
                    },
                    'anomalous_rules': {
                        'count': self.rule_anomalous_count,
                        'total_time_sec': round(self.rule_anomalous_time, 6),
                        'avg_time_ms': round(self.rule_anomalous_time / self.rule_anomalous_count * 1000, 4) if self.rule_anomalous_count > 0 else 0
                    }
                },
                'model_inference': {
                    'total_count': self.model_count,
                    'total_time_sec': round(self.total_model_time, 6),
                    'avg_time_sec': round(self.total_model_time / self.model_count, 6) if self.model_count > 0 else 0,
                    'avg_time_ms': round(self.total_model_time / self.model_count * 1000, 4) if self.model_count > 0 else 0
                },
                'speedup': round(
                    (self.total_model_time / self.model_count) / (self.total_rule_time / total_rule_count),
                    2
                ) if (total_rule_count > 0 and self.model_count > 0) else 0
            },
            'dataset_statistics': {
                'normal_dataset': {
                    'total': len(self.true_normal_results),
                    'by_rule': len(self.normal_by_rule),
                    'by_model': len(self.normal_by_model),
                    'correct_by_rule': sum(1 for r in self.normal_by_rule if r['predicted'] == "0"),
                    'correct_by_model': sum(1 for r in self.normal_by_model if r['predicted'] == "0")
                },
                'attack_dataset': {
                    'total': len(self.true_attack_results),
                    'by_rule': len(self.attack_by_rule),
                    'by_model': len(self.attack_by_model),
                    'correct_by_rule': sum(1 for r in self.attack_by_rule if r['predicted'] == "1"),
                    'correct_by_model': sum(1 for r in self.attack_by_model if r['predicted'] == "1")
                }
            },
            'method_performance': {
                'rule_engine': self._calculate_method_metrics(self.rule_results),
                'model_inference': self._calculate_method_metrics(self.model_results)
            }
        }
        
        metrics_file = os.path.join(self.output_dir, 'stage1_metrics.json')
        with open(metrics_file, 'w', encoding='utf-8') as f:
            json.dump(extended_metrics, f, ensure_ascii=False, indent=2)
        
        # âœ¨ ä¿®æ”¹ï¼šåˆ†åˆ«ä¿å­˜è¯¯æŠ¥å’Œæ¼æŠ¥åˆ°ä¸¤ä¸ªç‹¬ç«‹çš„ JSON æ–‡ä»¶ï¼ˆå…¨éƒ¨ä¿å­˜ï¼‰
        # ä¿å­˜è¯¯æŠ¥æ¡ˆä¾‹ï¼ˆFalse Positivesï¼‰
        fp_file = os.path.join(self.output_dir, 'stage1_false_positives.json')
        fp_data = {
            'total_count': len(self.fp_results),
            'by_rule': len([r for r in self.fp_results if r.get('detection_method') in ['rule_normal', 'rule_anomalous']]),
            'by_model': len([r for r in self.fp_results if r.get('detection_method') == 'model']),
            'cases': self.fp_results  # ä¿å­˜å…¨éƒ¨è¯¯æŠ¥æ¡ˆä¾‹
        }
        with open(fp_file, 'w', encoding='utf-8') as f:
            json.dump(fp_data, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ¼æŠ¥æ¡ˆä¾‹ï¼ˆFalse Negativesï¼‰
        fn_file = os.path.join(self.output_dir, 'stage1_false_negatives.json')
        fn_data = {
            'total_count': len(self.fn_results),
            'by_rule': len([r for r in self.fn_results if r.get('detection_method') in ['rule_normal', 'rule_anomalous']]),
            'by_model': len([r for r in self.fn_results if r.get('detection_method') == 'model']),
            'cases': self.fn_results  # ä¿å­˜å…¨éƒ¨æ¼æŠ¥æ¡ˆä¾‹
        }
        with open(fn_file, 'w', encoding='utf-8') as f:
            json.dump(fn_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç¬¬ä¸€é˜¶æ®µç»“æœå·²ä¿å­˜: {stage1_all_file}")
        print(f"ğŸ’¾ è¯„ä¼°æŒ‡æ ‡å·²ä¿å­˜: {metrics_file}")
        print(f"ğŸ’¾ è¯¯æŠ¥æ¡ˆä¾‹å·²ä¿å­˜: {fp_file} (å…± {len(self.fp_results)} æ¡)")
        print(f"ğŸ’¾ æ¼æŠ¥æ¡ˆä¾‹å·²ä¿å­˜: {fn_file} (å…± {len(self.fn_results)} æ¡)")
    
    def _calculate_method_metrics(self, results: List[Dict]) -> Dict:
        """è®¡ç®—ç‰¹å®šæ–¹æ³•çš„æŒ‡æ ‡"""
        if not results:
            return {
                'total': 0,
                'accuracy': 0.0,
                'fpr': 0.0,
                'fnr': 0.0
            }
        
        tp = sum(1 for r in results if r['true_label'] == "1" and r['predicted'] == "1")
        tn = sum(1 for r in results if r['true_label'] == "0" and r['predicted'] == "0")
        fp = sum(1 for r in results if r['true_label'] == "0" and r['predicted'] == "1")
        fn = sum(1 for r in results if r['true_label'] == "1" and r['predicted'] == "0")
        
        total = len(results)
        accuracy = (tp + tn) / total * 100 if total > 0 else 0
        fpr = fp / (fp + tn) * 100 if (fp + tn) > 0 else 0
        fnr = fn / (fn + tp) * 100 if (fn + tp) > 0 else 0
        
        return {
            'total': total,
            'tp': tp,
            'tn': tn,
            'fp': fp,
            'fn': fn,
            'accuracy': round(accuracy, 2),
            'fpr': round(fpr, 2),
            'fnr': round(fnr, 2)
        }
    
    def generate_full_report(self, stage1_elapsed: float):
        """
        ç”Ÿæˆå®Œæ•´ç»Ÿè®¡æŠ¥å‘Š
        
        Args:
            stage1_elapsed: ç¬¬ä¸€é˜¶æ®µç”¨æ—¶ï¼ˆç§’ï¼‰
        """
        if len(self.all_results) == 0:
            print(f"\n{'='*60}")
            print(f"âš ï¸  è­¦å‘Šï¼šæ²¡æœ‰æ£€æµ‹ç»“æœ")
            print(f"{'='*60}")
            print(f"è¯·æ£€æŸ¥:")
            print(f"  1. æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
            print(f"  2. æ•°æ®æ–‡ä»¶æ˜¯å¦ä¸ºç©º")
            print(f"  3. æ–‡ä»¶è·¯å¾„é…ç½®æ˜¯å¦æ­£ç¡®")
            print(f"{'='*60}\n")
            return
        
        # 1. åŸºç¡€ç»Ÿè®¡
        self.print_stage1_basic_statistics(stage1_elapsed)
        
        # 2. æ··æ·†çŸ©é˜µ
        self.print_confusion_matrix()
        
        # 3. æ•´ä½“è¯„ä¼°æŒ‡æ ‡
        self.print_metrics()
        
        # 4. æ£€æµ‹æ–¹æ³•ç»Ÿè®¡
        self.print_detection_method_statistics()
        
        # 5. æ•°æ®é›† Ã— æ£€æµ‹æ–¹æ³•äº¤å‰ç»Ÿè®¡
        self.print_dataset_method_statistics()
        
        # 6. æ£€æµ‹æ–¹æ³•æ€§èƒ½å¯¹æ¯”
        self.print_method_performance_comparison()
        
        # 7. âœ¨ ä¿®æ”¹ï¼šé”™è¯¯åˆ†æï¼ˆç»ˆç«¯åªæ˜¾ç¤ºå‰3ä¸ªç¤ºä¾‹ï¼‰
        self.print_error_analysis(max_display=3)
        
        # 8. æ”»å‡»ç±»å‹åˆ†å¸ƒ
        self.print_attack_type_distribution()
        
        # 9. ä¿å­˜ç»“æœï¼ˆåŒ…æ‹¬å…¨éƒ¨è¯¯æŠ¥å’Œæ¼æŠ¥ï¼‰
        self.save_results()


def analyze_results(all_results: List[Dict], output_config: Dict, stage1_elapsed: float):
    """
    åˆ†æç¬¬ä¸€é˜¶æ®µç»“æœçš„ä¾¿æ·å‡½æ•°
    
    Args:
        all_results: æ‰€æœ‰æ£€æµ‹ç»“æœåˆ—è¡¨
        output_config: è¾“å‡ºé…ç½®å­—å…¸
        stage1_elapsed: ç¬¬ä¸€é˜¶æ®µç”¨æ—¶ï¼ˆç§’ï¼‰
    """
    analyzer = ResultStatistics(all_results, output_config)
    analyzer.generate_full_report(stage1_elapsed)


def print_stage2_statistics(elapsed_time: float, output_file: str, deep_results: List[Dict]):
    """
    æ‰“å°ç¬¬äºŒé˜¶æ®µæ·±åº¦åˆ†æç»Ÿè®¡
    
    Args:
        elapsed_time: ç¬¬äºŒé˜¶æ®µç”¨æ—¶ï¼ˆç§’ï¼‰
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        deep_results: æ·±åº¦åˆ†æç»“æœåˆ—è¡¨
    """
    if len(deep_results) == 0:
        print(f"\n{'='*60}")
        print(f"âš ï¸  ç¬¬äºŒé˜¶æ®µï¼šæ²¡æœ‰éœ€è¦æ·±åº¦åˆ†æçš„URL")
        print(f"{'='*60}\n")
        return
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ç¬¬äºŒé˜¶æ®µç»Ÿè®¡")
    print(f"{'='*60}")
    print(f"â±ï¸  æ€»ç”¨æ—¶: {elapsed_time:.2f} ç§’")
    print(f"ğŸ“ˆ å¹³å‡æ¯URLç”¨æ—¶: {elapsed_time/len(deep_results):.2f} ç§’")
    print(f"ğŸ“Š æ·±åº¦åˆ†æURLæ•°: {len(deep_results)}")
    print(f"ğŸ’¾ æ·±åº¦åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    print(f"{'='*60}")


def print_two_stage_summary(stage1_elapsed: float, stage2_elapsed: float):
    """
    æ‰“å°ä¸¤é˜¶æ®µæ£€æµ‹æ€»ç»“
    
    Args:
        stage1_elapsed: ç¬¬ä¸€é˜¶æ®µç”¨æ—¶ï¼ˆç§’ï¼‰
        stage2_elapsed: ç¬¬äºŒé˜¶æ®µç”¨æ—¶ï¼ˆç§’ï¼‰
    """
    total_elapsed = stage1_elapsed + stage2_elapsed
    print(f"\n{'='*60}")
    print(f"ğŸ¯ ä¸¤é˜¶æ®µæ£€æµ‹å®Œæˆ")
    print(f"{'='*60}")
    print(f"â±ï¸  ç¬¬ä¸€é˜¶æ®µç”¨æ—¶: {stage1_elapsed:.2f} ç§’")
    print(f"â±ï¸  ç¬¬äºŒé˜¶æ®µç”¨æ—¶: {stage2_elapsed:.2f} ç§’")
    print(f"â±ï¸  æ€»ç”¨æ—¶: {total_elapsed:.2f} ç§’")
    print(f"{'='*60}\n")